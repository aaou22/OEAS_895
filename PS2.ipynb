{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#load unknown wine dataset\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#assign name to wine dataset\n",
    "wine=load_wine()\n",
    "#print dataset attributes for wine dataset\n",
    "print(wine['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#double check that wine.target is our wine type target variable\n",
    "print (wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "#define variables for machine learning\n",
    "x=wine.data \n",
    "y=wine.target \n",
    "#print shapes to double check that x and y have been properly assigned\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 1 2 0 1 0 1 1 0 2 2 0 1 0 1 1 2 1 2 1 2 0 2 1 1 2 2 0 1 0 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "#import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split into train and test sets --> 0.2 = 20% test, 80% train\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=4)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale the training data\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have commented out scaling here.  When I scale the data, almost all combinations of layers and nodes returns a score of >0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
      "(1, 2, 3)\n",
      "[1]\n",
      "1 1 0.2777777777777778\n",
      "1 2 0.3611111111111111\n",
      "1 3 0.3611111111111111\n",
      "1 4 0.5833333333333334\n",
      "1 5 0.9166666666666666\n",
      "[[10  0  0]\n",
      " [ 1 12  0]\n",
      " [ 0  2 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       0.86      0.92      0.89        13\n",
      "           2       1.00      0.85      0.92        13\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "1 6 0.2777777777777778\n",
      "1 7 0.3611111111111111\n",
      "1 8 0.0\n",
      "1 9 0.3611111111111111\n",
      "1 10 0.9722222222222222\n",
      "[[10  0  0]\n",
      " [ 1 12  0]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "[1 1]\n",
      "2 1 0.3611111111111111\n",
      "2 2 0.6111111111111112\n",
      "2 3 0.3611111111111111\n",
      "2 4 0.2777777777777778\n",
      "2 5 0.4166666666666667\n",
      "2 6 0.3611111111111111\n",
      "2 7 0.3611111111111111\n",
      "2 8 0.3611111111111111\n",
      "2 9 0.3611111111111111\n",
      "2 10 0.3611111111111111\n",
      "[1 1 1]\n",
      "3 1 0.2777777777777778\n",
      "3 2 0.2777777777777778\n",
      "3 3 0.3611111111111111\n",
      "3 4 0.6111111111111112\n",
      "3 5 0.6388888888888888\n",
      "3 6 0.3611111111111111\n",
      "3 7 0.3611111111111111\n",
      "3 8 0.3611111111111111\n",
      "3 9 0.3055555555555556\n",
      "3 10 0.3611111111111111\n"
     ]
    }
   ],
   "source": [
    "#import sklearn packages\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#create empty lists\n",
    "scores=[]\n",
    "scores_list=[]\n",
    "results=[]\n",
    "\n",
    "#create a range of numbers of nodes to be tested (1-10)\n",
    "n = tuple(range(1, 11, 1))\n",
    "print(n)\n",
    "#create a range of numbers of layers to be tested (1-3)\n",
    "l = tuple(range(1,4,1))\n",
    "print(l)\n",
    "\n",
    "#build a nested loop to loop through both various numbers of layers and nodes\n",
    "for l in l:\n",
    "    layers = np.ones(l, dtype=np.int8) #create an array of ones that loops with l\n",
    "    print(layers)\n",
    "    for i in n:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(i*layers), max_iter=2500, random_state=1) #1000 iterations wasn't enough to optimize\n",
    "        mlp.fit(X_train, y_train)\n",
    "        y_pred = mlp.predict(X_test)\n",
    "        scores = metrics.accuracy_score(y_test,y_pred)\n",
    "        print(l,i,scores)\n",
    "        scores_list.append(metrics.accuracy_score(y_test,y_pred))\n",
    "        if scores > 0.9:\n",
    "            print(confusion_matrix(y_test,y_pred))\n",
    "            print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLANATION OF RESULTS:\n",
    "\n",
    "1) Description of Loop: This nested for loop first loops through the number of layers in MLP Classifier (1,2,3 \"l\" in this case), and for each layer loops through various numbers of nodes (1-10 \"n\").  The result of the list will print 3 columns, with the number of layers in the left column, number of nodes in the middle column, and score in the right column.  Additionally, for any model run that returns a score >0.9, a confusion matrix and classification report are printed.  The random state of the model is set to 1, to ensure reproducibility between model runs.\n",
    "\n",
    "2) Results: Only two model runs returned a score of >0.9, those being 1 layer with 5 nodes, and 1 layer with 10 nodes.  See heat map below for visualization of scores.  The model run containing 1 layer and 10 nodes had the highest accuracy score (0.97, 35/36 predictions were correct) and will thus be used moving forward.  It is worth noting that required computational power should also be a factor in determining which model architecture to use, though those effects are negligible with the simple models tested here.\n",
    "\n",
    "3) Results cont: In addition to having a higher score, the confusion matrices and classification reports printed above show that the 1 layer, 10 node model perfectly predicts wines in \"class 2\" (3rd row) (recall score of 1.0) while the 5 node model incorrectly predicts 2 of them as class 1 (recall of 0.85).  The two models are identical in performace for class 0 and class 1, with 0 incorrect predictions for class 0 (recall of 1.0), and one misclassification of class 1 data into class 0 (recall of 0.92).  Recall scores here indicate how effectively the data from each class were classified as that given class.  Precision scores reveal false classifications for a given class.  A precision score of 0.91 for class 0 for both models indicates one false classification of \"class 0\" from non class 0 data.  The low precision of class 1 in the 5 node model (0.86) quantifies the 2 misclassifications of class 2 wine as class 1 wine.  High f1 scores across the board for both models indicate that there are no hidden discrepencies in the model performance despite its high score (ex: one really low precision or recall).\n",
    "\n",
    "FINAL DECISION: 1 layer, 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27777778 0.36111111 0.27777778]\n",
      " [0.36111111 0.61111111 0.27777778]\n",
      " [0.36111111 0.36111111 0.36111111]\n",
      " [0.58333333 0.27777778 0.61111111]\n",
      " [0.91666667 0.41666667 0.63888889]\n",
      " [0.27777778 0.36111111 0.36111111]\n",
      " [0.36111111 0.36111111 0.36111111]\n",
      " [0.         0.36111111 0.36111111]\n",
      " [0.36111111 0.36111111 0.30555556]\n",
      " [0.97222222 0.36111111 0.36111111]]\n"
     ]
    }
   ],
   "source": [
    "#create a matrix with layer, nodes, and scores\n",
    "\n",
    "#create an empty matrix (alter values to match n and l)\n",
    "matrix=np.zeros((10,3))\n",
    "#assign values for each set of layer runs to the array\n",
    "matrix[:,0] = scores_list[0:10]\n",
    "matrix[:,1] = scores_list[10:20]\n",
    "matrix[:,2] = scores_list[20:30]\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFXCAYAAADu/TSqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XtUVXX+//HXOSCIHMvKdMyRZJno\nWBk6paapIZKOpiiZkkaN6U9X5mUSFa94R8yZsclM01y6tIvoOF4qZyy8hFGpWaSWt9Iyu+iUmgIK\n4tm/P1rfM8OYgUc+bM7m+XCdtTiXvT9v+Ofl+7M/+3NclmVZAgAAZc5tdwEAADgVIQsAgCGELAAA\nhhCyAAAYQsgCAGAIIQsAgCHBdhfwS75YudbuEmDIuZN5dpcAQ6rXCre7BBjSILGnsXM3vbW938fu\n+eqdMqzEjAoZsgCAysHlctldglFMFwMAYAidLADANi6Xs3s9Z/92AADYiE4WAGAbt5x9TZaQBQDY\nxukLnwhZAIBt3A6/JkvIAgBs4/RO1tn/hQAAwEaELAAAhjBdDACwjYvVxQAAmMHCJwAADHH6widC\nFgBgGzche/WSkpJ08eLFYq9ZliWXy6WVK1eaGBIAgArHSMiOGjVKEydO1Pz58xUUFGRiCAAAKjwj\nIXvXXXcpPj5eBw8eVFxcnIkhAAAO4HL4naTGrskOHDjQ1KkBAA7BwicAAAxh4RMAAIY4fTMKZ0+G\nAwBgI0IWAABDmC4GANiGbRUBADCE1cUAABjC6mIAAAxhdTEAAPALnSwAwDZOX/jk7N8OAAAbVchO\n9tzJPLtLgCE7d3xjdwkwJLZblN0lIACxuhgAAENYXQwAgCGsLgYAAH6hkwUA2IZrsgAAGOL0a7JM\nFwMAYAidLADANk5f+ETIAgBsw45PAADAL3SyAADbsLoYAABDnL66uNxCtrCwUCEhIeU1HAAgADh9\n4VOZX5PdsmWLYmJiFBcXp40bN/peHzhwYFkPBQBAhVbmnezChQu1du1aWZalESNGqKCgQD179pRl\nWWU9FAAgwDFdfJWqVKmiGjVqSJJeeOEFPf7446pTp47jL24DAPC/yny6uG7dupo1a5by8/Pl8Xj0\n/PPPa9q0aTpy5EhZDwUACHAul8vvRyAo85BNS0tTo0aNfH+AOnXqaPny5frDH/5Q1kMBAAKc2+Xy\n+xEIyny6ODg4WAkJCcVeq1mzpiZMmFDWQwEAApzTVxdznywAwDaB0pH6i20VAQCO4/V6lZqaqj59\n+igpKUlfffVVsfeXLFmihIQEPfTQQ3r77beN1UEnCwBwnMzMTBUWFiojI0M5OTlKT0/XggULJEln\nz57VihUr9NZbb+n8+fPq0aOH4uLijNRByAIAbGNqlfDu3bvVtm1bSVJ0dLT27dvney8sLEy33HKL\nzp8/r/PnzxtdqUzIAgBsY+qabG5urjwej+95UFCQioqKFBz8c+zVqVNHXbt21aVLlzR48GAjNUhc\nkwUA2Mh1Df9+jcfjUV5enu+51+v1BWxWVpZOnjypzZs3a9u2bcrMzNSePXuM/H6ELADANqbuk23e\nvLmysrIkSTk5OYqKivK9d/3116tq1aoKCQlRaGioqlevrrNnzxr5/ZguBgA4TlxcnLKzs5WYmCjL\nspSWlqalS5cqIiJCsbGxeu+999S7d2+53W41b95cbdq0MVIHIQsAcBy3261p06YVe61Bgwa+n4cP\nH67hw4cbr4OQBQDYJlD2IPYXIQsAsI3Td3wiZFGuWrSsa3cJMOTcybySPwT8DzpZAAAMcfoXBHAL\nDwAAhtDJAgBs43Z2I0snCwCAKXSyAADbsPAJAABDuIUHAABDnN7Jck0WAABD6GQBALZxO/w+WUIW\nAGAbposBAIBfyqWTvXDhgtxut0JCQspjOABAgHD66mIjnezXX3+tIUOGKDU1Ve+99566dOmiLl26\naOvWrSaGAwAEKJfL/0cgMNLJjh8/XsOGDdM333yj4cOHa9OmTQoNDdXAgQMVExNjYkgAACocIyFb\nVFSkFi1aSJJ27Nihm2666efBgllnBQD4D6aL/RAZGakJEybI6/UqPT1dkrRo0SLVrFnTxHAAgADl\nuoZ/gcBIazljxgxt2bJFbvd/Mrx27dpKSkoyMRwAIEA5/RYeIyHrdrvVsWPHYq/Fx8ebGAoAgAqL\ni6QAANs4/ZosIQsAsI3DM5YdnwAAMIVOFgBgG6aLAQAwJFBuxfEXIQsAsI3TO1muyQIAYAidLADA\nNg5vZOlkAQAwhU4WAGAbtlUEAMAQpy98qpAhu+fj7+0uAYa06dTA7hJgyObXD9ldAgyJNnhuh2ds\nxQxZAEDl4PROloVPAAAYQsgCAGAI08UAANuwrSIAAIZwCw8AAIa4nZ2xhCwAwD5O72RZ+AQAgCGE\nLAAAhjBdDACwjdOniwlZAIBtnL7wyfh08Y8//mh6CABAgHK5XH4/AkGZd7JHjx4t9jwlJUWzZ8+W\nJEVGRpb1cACAABYgWem3Mg/Z/v37q2rVqqpVq5Ysy9LRo0eVmpoql8ul5cuXl/VwAABUWGUesmvW\nrNHkyZP1yCOPqE2bNkpKStKKFSvKehgAgAM4/Vt4yjxkb7rpJj377LOaPXu29u7dW9anBwAgYBhZ\n+BQcHKwJEyb4powBAPglrmv4FwiM3sKTkJCghIQEk0MAAAKYw2eLuU8WAGAfp1+TZVtFAAAMoZMF\nANjG1KYSXq9XU6ZM0cGDBxUSEqIZM2bo1ltv9b3/zjvvaP78+ZKkJk2aaPLkyUZqoZMFANjG5fL/\n8WsyMzNVWFiojIwMJScnKz093fdebm6u5syZo4ULF2rVqlWqW7euTp8+beT3I2QBAI6ze/dutW3b\nVpIUHR2tffv2+d77+OOPFRUVpdmzZ6tv376qWbOmbrzxRiN1MF0MALCNqeni3NxceTwe3/OgoCAV\nFRUpODhYp0+f1o4dO7Ru3TpVq1ZN/fr1U3R0tJGtf+lkAQC2cbv8f/waj8ejvLw833Ov16vg4J/7\nyho1aujOO+/UzTffrPDwcN19993av3+/md/PyFkBALBR8+bNlZWVJUnKyclRVFSU77077rhDhw4d\n0qlTp1RUVKRPPvlEt912m5E6mC4GANjG1HRxXFycsrOzlZiYKMuylJaWpqVLlyoiIkKxsbFKTk7W\nwIEDJUmdO3cuFsJliZAFANjG1F4Ubrdb06ZNK/ZagwYNfD937dpVXbt2NTP4fyFkAQC2cfqOTxUy\nZBe/l2V3CTCkYUMzy+RhvwsXi+wuAahwKmTIAgAqB1PXZCsKVhcDAGAInSwAwDYOb2QJWQCAfSr9\ndPGxY8e0YcMGWZalSZMm6aGHHtLevXvLozYAgMOZ+oKAiqLEkB03bpy8Xq82b96sL7/8UuPGjdPM\nmTPLozYAgMO5XS6/H4GgxJAtKChQjx49tHXrVnXr1k133323CgsLy6M2AAACWokhGxQUpE2bNmnb\ntm26//77lZmZKbebRckAAJSkxLScNm2atm3bpsmTJ6tWrVp68803NWPGjPKoDQDgcJX+mmyjRo00\nZMgQhYSE6NKlSxo5cqQaN25cHrUBABzO5XL5/QgEJYbsxo0bNWTIEM2cOVNnzpxRYmKi1q9fXx61\nAQAcrtJ3sosXL9Zrr72m8PBw3XTTTVq7dq0WLVpU6gG8Xq9OnDghr9d7TYUCAJyn0neybrdbHo/H\n97xWrVolLnwaP368JOmTTz5Rp06dNHToUD344IPKycm5xnIBAAgcJe741LBhQ7388ssqKirS/v37\n9eqrr5Z4Tfb48eOSpLlz52rx4sWqX7++Tpw4oeTkZL388stlUzkAABVciZ1samqqTpw4odDQUI0f\nP14ej0eTJ08u1cmDgoJUv359SVLt2rWZMgYAFOP0a7IldrLVqlVTcnKykpOTS33Sc+fOKSEhQfn5\n+Vq9erW6d++u9PR03XLLLddULADAWQJl5yZ/XTFkGzduXOzCcnBwsIKCglRQUCCPx6Ndu3Zd8aRr\n165VYWGhDhw4oKpVq8rlcikqKkq9evUq2+oBAAEtUDL2+PHj+vzzz9W2bVt9++23qlevXqmOu2LI\nHjhwQJI0efJkNW/eXN27d5fL5dKmTZu0ffv2Ek8cEhKipk2b+p4/8sgjpSoIAFB5BMIq4Y0bN2rB\nggU6f/68MjIylJiYqDFjxig+Pr7EY0u8Jrtnzx7Fx8f7/hCdOnXSvn37rr1qAAACwP/dyurxeK76\nVtYSQzYsLExr1qxRfn6+cnNz9corr+j666+/5qIBAAiEhU/+3MrqO7akD8yZM0dvv/222rRpo/bt\n2+uDDz7QM88843+1AAAEkP+9lXXSpEml3l64xNXFdevW1bx583TkyBFdunRJUVFRCg4u8TAAAEoU\nCNdkU1NTtWDBAt+trK1atVJKSkqpji0xLffu3asRI0aoRo0a8nq9+uGHHzR//nzddddd11w4AKBy\nC4CM1fTp0zVr1qyrupX1/5QYsjNnztTcuXN9oZqTk6Pp06fr73//+9VXCgDAfwmETvbQoUPKy8tT\neHj4VR9bYsjm5+cX61qjo6NVUFBw1QMBABCI3G63YmJiFBkZqdDQUN/ry5cvL/HYEkP2+uuvV2Zm\npjp27ChJyszMVI0aNa6hXAAAfhYAjaxGjx7t97Elhuz06dM1evRoTZgwQZJUr149VhcDAMpEIEwX\nt2jRQu+8844++OADFRUVqWXLlr7GsyQlhmz9+vW1evVq5efny+v1FrtXCAAAp1u8eLHeeustdevW\nTZZlaeHChTp8+LCefPLJEo8tMWQ/++wzLVy4UD/99JMsy/K9Xpq5aAAAfk0ANLLasGGDVq9erapV\nq0qSevfurYSEhLIJ2ZSUFPXp00cNGzYst7Z+2dT+5TIOyt+5k3l2lwBD2t13q90lIAAFwrfwWJbl\nC1hJCg0NLfV+ESV+qmrVqnr00Uf9rw4AgCsIgIxVq1atNGzYMPXs2VPSz98017Jly1IdW2LI3nff\nfVqxYoXuu+++YkuX+W5YAEBlMGHCBL322mtat26dLMtSq1at1KdPn1IdW2LIrl+/XpK0dOlS32su\nl0ubN2/2s1wAAH4WCKuL8/PzZVmWnnvuOZ04cUIrV67UxYsXSzVlXOIntmzZUiZFAgDwvwIgY5Wc\nnKxGjRpJksLDw+X1ejVmzBjNmzevxGNL9109AABUUt9++62efvppSZLH49HTTz+tY8eOlepYQhYA\nYBuX2+X3o9xqdLl08OBB3/Mvvvji2lcXz5kzR6NHj1ZWVpbatWt37VUCAPA/AmG6OCUlRU888YRq\n164tl8ulU6dOac6cOaU69ooh+/rrr6tNmzaaOXOmqlWrVmwjCkm65557rq1qAAAquK1bt+q2227T\n1q1btXz5cmVlZally5al/rrXK4bs0KFD9eKLL+rkyZP629/+Vuw9l8vFjk8AgGtWkVcXL1myRBs3\nbtTs2bN15MgRPf/885owYYL279+vZ555xren/6+5Ysj27t1bvXv31vz58/XUU0+VaeEAAEgVe7p4\n/fr1ysjIUFhYmP785z+rQ4cOevjhh2VZlrp06VKqc5R45bZ///6aM2eO3n//fV26dEmtWrXSiBEj\nVK1atWv+BQAAlVtF7mRdLpfCwsIkSTt27FDfvn19r5dWiauLp0+frvPnzystLU2zZ8/WxYsXNXny\n5Ksq9NSpU5dd0wUAoCILCgrS2bNn9f3332v//v1q06aNJOmbb74pu72LP/30U23YsMH3PDU1tcQ2\nec2aNfruu+8UExOj5ORkhYaG6sKFC5o8ebJat25dqsIAAM5XgRtZDRo0SD169FBRUZF69eqlWrVq\naePGjZo7d26pL6OWGLKWZens2bO67rrrJElnz55VUFDQrx7z6quvasWKFXryySe1YMECRUZG6sSJ\nExoyZAghCwAICJ07d1azZs10+vRpNW7cWNLPOz7NmDGj7L4g4I9//KMefvhhxcTESPp5m8VBgwb9\n6jFVqlRRtWrVFB4ernr16kmS7/4iAAB8Kngu1K5dW7Vr1/Y9b9++/VUdX2LIPvTQQ7rzzju1a9cu\neb1ezZs3z7eH45V06NBBTz75pKKiojR48GC1bdtW27dvV6tWra6qOACAszm9+SrVlduoqChFRUWV\n+qSDBg3Szp079e677+qWW27Rjz/+qKSkJN1///3+1gkAcCCHZ2zpQtYfLVq0UIsWLUydHgDgAOW5\nB7Ed+IIAAAAMuWLIrl69WkeOHFGvXr18r/33zwAA4Nddcbq4sLBQ8+fP1+HDh5WUlKTbbrtNP/74\now4cOKBGjRo5/mI1AMA8p0fJFTvZfv366S9/+YsiIyP14osvqnv37rIsS8uXL9fDDz9cnjUCABzK\n5XL5/QgEV+xke/bsqcjISJ09e1Z79uxRVFSUbrjhBqWlpZVnfQAABzOVlV6vV1OmTNHBgwcVEhKi\nGTNm6NZbb73sM4MGDVJsbKweeeQRI3VcsZNdu3athg0bpqKiIm3fvl1jx47Vl19+qaeeekqLFy82\nUgwAoHIx1clmZmaqsLBQGRkZSk5OVnp6+mWfefbZZ/XTTz+Z+tUklXALT2RkpBo2bKjRo0dLkgYM\nGKCJEyfq448/NloUAADXYvfu3Wrbtq0kKTo6Wvv27Sv2/r/+9S+5XC61a9fOaB0l3sKzZMmSYj/X\nqVOn1N+jBwCAHXJzc+XxeHzPg4KCVFRUJEk6dOiQ3njjDY0YMcJ4HcY2owAAoCSmrsl6PB7l5eX5\nnnu9Xt/X061bt04nTpzQ448/rm+++UZVqlRR3bp1jXS1hCwAwDamVgk3b95cW7duVZcuXZSTk1Ns\na+AxY8b4fp43b55q1qxpbNqYkAUA2MfQvoNxcXHKzs5WYmKiLMtSWlqali5dqoiICMXGxpoZ9BdU\nyJA9dzKv5A8BAAKeqU7W7XZr2rRpxV5r0KDBZZ8bNmyYkfF9dRg9OwAAlRghCwCAIRVyuhgAUDkE\nyO6IfiNkAQC2CZQ9iP1FyAIAbOPwjCVkAQA2cnjKsvAJAABD6GQBALZxuelkAQCAH+hkAQC2cfgl\nWUIWAGAfp9/CY2S6ODc318RpAQAO43L5/wgERkK2TZs2Wr16tYlTAwAQMIyEbOPGjbV//3499thj\n2rlzp4khAABO4PBW1sg12dDQUKWmpmrv3r1atGiRpk2bpnvvvVf16tXTY489ZmJIAEAAcvotPEZC\n1rIsSdKdd96pefPm6dy5c9q1a5eOHj1qYjgAACokIyGbkJBQ7Hn16tXVoUMHE0MBAAJYgMz6+s1I\nyPbs2dPEaQEATuPwlGXHJwAADGEzCgCAbRzeyBKyAAD7sLoYAABD2FYRAAD4hU4WAGAfZzeydLIA\nAJhCJwsAsI3Tr8kSsgAA2xCyAACY4vCLloQsAMA2dLI2aPLHP9hdAgz5bNk/7S4BAMqNwxt1AADs\nUyE7WQBA5cB0MQAApjg7YwlZAIB9+IIAAABMcfh0MQufAAAwhJAFAMAQposBALZx+GwxIQsAsA+3\n8AAAYAqriwEAMMPpnWy5LHwqLCzUhQsXymMoAAAqDCMhe/ToUQ0fPlzJycnKyclRt27d1LVrV23c\nuNHEcACAQOW6hkcAMDJdPGnSJA0ZMkTnzp3T4MGDtWHDBlWvXl39+/dXly5dTAwJAECFY6STLSoq\nUuvWrfXAAw+oRo0aql27tqpVq6bgYC4BAwD+w+Vy+f0IBEZSr27dunr66ad16dIlhYeHa+7cufJ4\nPLr55ptNDAcACFDsXeyH2bNn65133lH9+vUVHh6uZcuWqWrVqkpLSzMxHAAgUAVIR+ovIyEbHBys\n2NhY3/OxY8eaGAYAEOACZdrXX+xdDACAIaxEAgDYx9mNLJ0sAACm0MkCAGzD6mIAAExx+MInQhYA\nYBtTq4u9Xq+mTJmigwcPKiQkRDNmzNCtt97qe3/ZsmV68803JUnt27fX0KFDjdTBNVkAgONkZmaq\nsLBQGRkZSk5OVnp6uu+9r7/+Whs2bNDKlSuVkZGhd999VwcOHDBSB50sAMA+hq7J7t69W23btpUk\nRUdHa9++fb73fvOb3+ill15SUFCQpJ+3Ag4NDTVSByELALCNqeni3NxceTwe3/OgoCAVFRUpODhY\nVapU0Y033ijLsvTMM8+oSZMmioyMNFIH08UAAMfxeDzKy8vzPfd6vcW+pKagoECjRo1SXl6eJk+e\nbKwOQhYAYB9D3yfbvHlzZWVlSZJycnIUFRXle8+yLA0ZMkSNGjXStGnTfNPGJlTI6eLPlv3T7hIA\nXKWw681c04KzmZoujouLU3Z2thITE2VZltLS0rR06VJFRETI6/Vq586dKiws1Pbt2yVJI0eOVLNm\nzcq8jgoZsgAAXAu3261p06YVe61Bgwa+n/fu3VsudRCyAAD7sOMTAABmOP2r7ghZAIB9HB6yrC4G\nAMAQOlkAgG2cPl1MJwsAgCF0sgAA+7C6GAAAM5w+XUzIAgDsQ8heG8uyHP8/FQCAf1xMF1+9Y8eO\naerUqTpy5IhOnjyp22+/XfXq1dPYsWN18803mxgSAIAKx8jq4qlTp2rixInaunWrXnnlFbVu3Vr9\n+/fXhAkTTAwHAECFZCRkc3NzfV+AGx0drY8++kh33HGHzp49a2I4AECgcrn8fwQAI9PFv/3tb5Wa\nmqp27dpp27Zt+t3vfqe33npLYWFhJoYDAAQop6/ZMdLJzpo1S40aNVJ2draaNm2qMWPGqFatWvrr\nX/9qYjgAQKCik716ISEh6tevX7HXoqOjTQwFAAhgTl9dzLaKAAAYQsgCAGAIOz4BAOwTINdW/UXI\nAgDsQ8gCAGCG02/hIWQBAPZhdTEAAPAHnSwAwDYul7N7PWf/dgAA2IhOFgBgHxY+AQBgBquLbfDY\nXxbbXQIMWZ78/+wuAYac/6nA7hIQiFhdDAAA/FEhO1kAQOXAdDEAAKY4PGSZLgYAwBA6WQCAfRy+\nGQUhCwCwjYvVxQAAwB90sgAA+zh84RMhCwCwDbfwAABgisMXPjn7twMAwEZ0sgAA27C6GAAA+IVO\nFgBgHxY++SczM1Pvv/++zp07p+uuu06///3v1blzZ8evJAMAlJ7TM8FIyE6dOlVer1ft2rVTeHi4\n8vLylJWVpXfffVczZ840MSQAIBA5fHWxkZA9fPiwXn755WKvxcbGKjEx0cRwAIBAxcKnq+f1evXh\nhx8We23Xrl2qUqWKieEAAKiQjHSy6enpmjVrlkaOHCnLsuR2u9WkSRNNnz7dxHAAAFRIRkI2IiJC\nCxYsMHFqAICDsPDJD0lJSbp48eIvvrdy5UoTQwIAAhELn67eqFGjNHHiRM2fP19BQUEmhgAAOACd\nrB/uuusuxcfH6+DBg4qLizMxBADACehk/TNw4EBTpwYAICA4+78QAADYiL2LAQC24Vt4AAAwxeXy\n//ErvF6vUlNT1adPHyUlJemrr74q9v6qVauUkJCg3r17a+vWrcZ+PTpZAIBtXIYWPmVmZqqwsFAZ\nGRnKyclRenq6b/+Gf//731qxYoXWrFmjgoIC9e3bV23atFFISEiZ10EnCwCwj6FOdvfu3Wrbtq0k\nKTo6Wvv27fO9t2fPHjVr1kwhISGqXr26IiIidODAASO/XoXsZPd89Y7dJQAAykHIdTcZOW9ubq48\nHo/veVBQkIqKihQcHKzc3FxVr17d9154eLhyc3ON1EEnCwBwHI/Ho7y8PN9zr9er4ODgX3wvLy+v\nWOiWJUIWAOA4zZs3V1ZWliQpJydHUVFRvveaNm2q3bt3q6CgQOfOndMXX3xR7P2y5LIsyzJyZgAA\nbOL1ejVlyhQdOnRIlmUpLS1NWVlZioiIUGxsrFatWqWMjAxZlqXBgwerU6dORuogZAEAMITpYgAA\nDCFkAQAwhJC12SeffKKkpCS7y0AZunjxokaPHq2+ffuqV69e2rx5s90loYxcunRJ48aNU2Jiovr1\n66djx47ZXRIquAp5n2xlsXjxYm3YsEFhYWF2l4IytGHDBtWoUUNz5szR6dOn1bNnT8XGxtpdFsrA\n/22/t3LlSu3YsUOzZs3y7SIE/BI6WRtFRERo3rx5dpeBMta5c2eNGDHC9zwoKMjGalCWOnbsqOnT\np0uSvv32W9WsWdPmilDR0cnaqFOnTjp+/LjdZaCMhYeHS/p5x5nhw4frT3/6k80VoSwFBwcrJSVF\nb7/9tp577jm7y0EFRycLGPDdd9/pscceU3x8vLp162Z3OShjs2fP1qZNmzRp0iTl5+fbXQ4qMEIW\nKGM//PCDnnjiCY0ePVq9evWyuxyUoXXr1unFF1+UJIWFhcnlcnE5AL+KkAXK2MKFC3X27Fm98MIL\nSkpKUlJSki5cuGB3WSgDDzzwgD777DP169dPAwYM0Pjx4xUaGmp3WajA2PEJAABD6GQBADCEkAUA\nwBBCFgAAQwhZAAAMIWQBADCEkEWl1qNHD0nSK6+8olWrVpX6uFWrVqlt27aaPXt2sdc7dOjALl4A\nfNhWEZXW0aNHVb9+fUnSRx99pCFDhpT62DfeeEOzZs3SfffdZ6g6AE5AyKJSGjBggA4dOqTg4GDF\nx8fr6NGjOnr0qP7xj38U+9yaNWu0dOlSuVwu3X777Zo0aZKWLl2qvXv3aurUqZo4caLat29/2flz\nc3M1fvx4nThxQidPntS9996rmTNnasyYMbrnnnvUu3dvSVJSUpJGjRqlGjVqaMqUKTpz5oyqVq2q\nSZMmqUmTJho7dqzOnDmjr776SqNHj9auXbuUnZ0tt9utjh07aujQoeXy9wLgJwuopNLT063s7Gzr\n3LlzVt++fS97/8CBA1bHjh2tU6dOWZZlWVOmTLHS09Mty7KsRx991Prggw8uOyYmJsb6+uuvrddf\nf9164YUXLMuyrIKCAqtjx47W3r17rffff9831vHjx60uXbpYlmVZffr0sT799FPLsizr8OHD1gMP\nPGBZlmWlpKRYKSkpl30+Pz/fGjFihHXhwoUy+3sAKHt0sqi0Pv/8cw0cOFCHDx9Ww4YNL3t/165d\niomJ0Q033CBJ6tOnj8aNG1eqcz/44IPas2ePli1bpiNHjujMmTPKz89Xy5YtNWnSJB0/flzr169X\nfHy88vLytG/fvmLnzs/P1+nYAgr0AAACCElEQVTTpyVJTZs2lSTVrl1boaGhSkxMVExMjEaNGsWW\nfkAFR8iiUhowYIA+/PBDPfHEEzpz5owkac+ePcWmi71eb7FjLMtSUVFRqc6/YsUKbdq0Sb1791br\n1q116NAhWZYll8ulHj166M0339Q///lPLVmyRF6vVyEhIVq/fr3v+O+//141atSQJFWtWlXSz1+x\ntnr1au3cuVNZWVlKTEzUihUrFBkZeU1/CwDmsLoYldL06dPVunVrrV+/Xq1bt9aCBQsuux7bokUL\nbdmyxRfCq1atUsuWLUt1/uzsbPXp00fdu3dXQUGBDhw44AvthIQErVy5UnXq1FHt2rVVvXp11a9f\n3xey2dnZ6tev32Xn/Oyzz/Too4/qnnvuUUpKiho0aKCjR49ey58BgGF0sqiUcnJy1KxZM0nSwYMH\n1ahRo8s+07hxYw0ePFhJSUm6ePGibr/9dk2dOrVU53/88cc1ZcoULVq0SB6PR82aNfPd2lOnTh3V\nqVNHPXv29H1+zpw5mjJlil566SVVqVJFc+fOlcvlKnbOJk2aKDo6Wg8++KDCwsLUvHlztWvXzt8/\nAYBywLfwAOXIsiydPHlSSUlJeuONNxQSEmJ3SQAMYroYKEebNm1SfHy8Ro4cScAClQCdLAAAhtDJ\nAgBgCCELAIAhhCwAAIYQsgAAGELIAgBgCCELAIAh/x+UJXOEGp4T3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create heat map of MLP accuracies with various nodes and layers\n",
    "import seaborn\n",
    "l = range(1,4,1) #redifining l (its values were lost somewhere along the way) \n",
    "heatmap=seaborn.heatmap(matrix, xticklabels=l, yticklabels=n, cbar_kws={'label': 'Score'})\n",
    "plt.xlabel('# of layers')\n",
    "plt.ylabel('# of nodes')\n",
    "plt.show(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 2 1 1 1 1 1]\n",
      "[[1.00000000e+00 8.02126135e-18 6.84556082e-12]\n",
      " [9.99969976e-01 2.35594599e-08 3.00005335e-05]\n",
      " [9.91639432e-01 6.28081206e-03 2.07975643e-03]\n",
      " [7.12805585e-04 9.42443448e-01 5.68437464e-02]\n",
      " [2.71841017e-02 4.95834183e-02 9.23232480e-01]\n",
      " [1.17476849e-01 8.67489885e-01 1.50332660e-02]\n",
      " [7.51261652e-03 5.11426298e-01 4.81061086e-01]\n",
      " [1.89799272e-02 9.80745329e-01 2.74743877e-04]\n",
      " [1.01416042e-04 9.62873048e-01 3.70255362e-02]\n",
      " [5.43745252e-04 9.96545154e-01 2.91110071e-03]]\n"
     ]
    }
   ],
   "source": [
    "#test high scoring model on unknown_wine data to predict class of wine\n",
    "unknown_wine = pd.read_csv('C:/Users/Austin/Desktop/OEAS895_Clayton/unknown_wine.csv') #read in data\n",
    "#print(unknown_wine)\n",
    "#run classifier with high scoring model (1 layer, 10 nodes)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=2500, random_state=1) #preserve iterations and random state used for model verification\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(unknown_wine)\n",
    "#predict the probability that each target data point is put into each class\n",
    "probability = mlp.predict_proba(unknown_wine)\n",
    "print(y_pred) #class predictions for each of the 10 unknown samples\n",
    "print(probability) #matrix that reports the probability of each sample (row) belonging to each class (column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The probability matrix above shows that each unknown wine has a probability near or above 0.9 of being classified into its predicted class, with the exception of the 7th unknown wine, which was classified as \"class 1\" with a probability of only 0.51 for it actually belonging to that class.  Further investigation of that sample should be conducted before completely accepting the results of the classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
